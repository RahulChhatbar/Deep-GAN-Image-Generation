# GAN Training for CIFAR-10 Image Generation

## Objective

The objective of this project is to implement and train a **Generative Adversarial Network (GAN)** to generate realistic images from random noise. The model is trained using the **CIFAR-10** dataset, which consists of 60,000 32x32 color images across 10 classes. The generator aims to produce images that resemble the real CIFAR-10 images, while the discriminator tries to distinguish between real and generated images.

## Overview

In this project, we use a **Generator-Discriminator architecture**, where:

- **Generator**: A deep neural network that generates synthetic images from random noise. It aims to learn the distribution of real images and create new samples that resemble real images.
- **Discriminator**: A convolutional neural network that distinguishes between real and fake images. It classifies input images as either real (from the dataset) or fake (generated by the generator).

The model is trained with the **CIFAR-10** dataset, and during training, both models (generator and discriminator) are updated to improve their respective tasks: the generator gets better at generating realistic images, and the discriminator gets better at distinguishing real from fake.

The training process involves optimizing the **Binary Cross-Entropy Loss** for both models. The generator and discriminator are updated using **backpropagation** and **gradient descent**.

## Directory Structure

```plaintext
│
├── 041---Assignment-4---Generative-Adversarial-Networks.pdf  # Assignment instructions and details.
├── README.md  # This file
├── requirements.txt  # List of dependencies for the project
└── src  # Source code and Jupyter notebooks
    └── cifar10_gan.ipynb  # Jupyter notebook implementing GAN for CIFAR-10 image generation.
└── output  
    ├── run_1  # Results and models from the first training run (50 epochs)
    │   ├── generated_images  # Folder with images generated at different epochs.
    │   ├── models  # Trained models (generator.h5, discriminator.h5).
    │   ├── losses.csv  # CSV file containing generator and discriminator losses per epoch.
    │   └── losses_plot.png  # Plot of generator and discriminator losses.
    └── run_2  # Results and models from the second training run (250 epochs)
        ├── generated_images  # Folder with images generated at different epochs.
        ├── models  # Trained models (generator.h5, discriminator.h5).
        ├── losses.csv  # CSV file containing generator and discriminator losses per epoch.
        └── losses_plot.png  # Plot of generator and discriminator losses.

```

## Requirements

Before running the code, ensure you have the necessary dependencies installed. You can install them using:

```bash
pip install -r requirements.txt
```

## Results

After training for 50 epochs and 250 epochs, the following are saved:

- **Generated Images**: Images at regular intervals (every 10 epochs or the final epoch).
- **Losses**: Generator and discriminator losses are plotted and saved.
- **Models**: The trained generator and discriminator models are saved as `generator.h5` and `discriminator.h5`.

Here is an example of the generated image from **Run 2 (250th Epoch)**:

<p align="center">
  <img src="../output/run_2/generated_images/image_at_epoch_0250.png" alt="Generated Image at Epoch 250"/>
</p>